# Project name for wandb logging
project_name: Velocity_VS_Random_VS_SU
# Change run_dir to where you want to save the model
run_dir: null
manual_seed: 0
resume: 0
# Change to 0 for single training and 1 for wandb sweep
wandb_sweep: 1

data_provider:
  dataset: vww
  root: /data/datasets/
  resize_scale: 0.08
  color_aug: 0.4
  base_batch_size: 32
  n_worker: 12
  image_size: 224
  # Number of classes in target dataset for classifier head dimensions
  new_num_classes: 2
  
  # For c10, c100, vww, food101, pets and cub200 (except flowers102 because it already has a validation set)
  validation_percentage: 0.2 #(use to divide train set into train and validation)

run_config:
  n_epochs: 200
  base_lr: 0.125
  warmup_epochs: 5
  warmup_lr: 0
  lr_schedule_name: cosine

  # wd
  weight_decay: 0
  no_wd_keys: ['norm', 'bias']
  # optimizer
  optimizer_name: sgd
  momentum: 0
  # how many epoch should the model perform testing
  test_per_epochs: 1

net_config:
  net_name: mbv2
  fine_tuning: true

NEq_config:
  # Total number of parameters in the network
  total_num_params: 2189760
  # Ratio of total number of parameters to use as budget
  ratio: 1
  # In case we need to update a specific number of budget of updatable parameter instead of the ratio, only use with scheme "scheme_fixed_budget"
  budget: 123456
  # Placeholder for budget expressed in maximal number of trainable parameters
  glob_num_params: 599040
  velocity_mu: 0.5
  neuron_selection: velocity # chose between SU, velocity, random and full
  initialization: random # chose between SU, random and full

backward_config:  # for partial backward
  n_bias_update: 31  # how many conv to update the bias
  weight_update_ratio: 1-1-1-1-1-0.5-1-1  # how many weights along input channels are updated (also support int number) (percentage)
  manual_weight_idx: 27-30-33-36-39-42-45-48 # index of layer to be updated by SU
